{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgBRxdkiLmpq",
        "outputId": "cc5787fa-1d90-4e49-bc8b-5d415558ba65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Dataset class and helper functions in dataset.py\n",
        "%%writefile dataset.py\n",
        "from glob import glob\n",
        "from os import path\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ImagesDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels_file, width=100, height=100, dtype=None):\n",
        "        self.image_filepaths = sorted(path.abspath(f) for f in glob(path.join(image_dir, \"*.jpg\")))\n",
        "        self.filenames_classnames, self.classnames_to_ids = ImagesDataset.load_classnames(labels_file)\n",
        "        if width < 100 or height < 100:\n",
        "            raise ValueError('width and height must be greater than or equal 100')\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.dtype = dtype\n",
        "\n",
        "    @staticmethod\n",
        "    def load_classnames(labels_file):\n",
        "        filenames_classnames = np.genfromtxt(labels_file, delimiter=';', skip_header=1, dtype=str)\n",
        "        classnames = np.unique(filenames_classnames[:, 1])\n",
        "        classnames.sort()\n",
        "        classnames_to_ids = {classname: index for index, classname in enumerate(classnames)}\n",
        "        return filenames_classnames, classnames_to_ids\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        with Image.open(self.image_filepaths[index]) as im:\n",
        "            image = np.array(im, dtype=self.dtype)\n",
        "        image = to_grayscale(image)\n",
        "        resized_image, _ = prepare_image(image, self.width, self.height, 0, 0, 32)\n",
        "        resized_image = torch.tensor(resized_image, dtype=torch.float32) / 255.0\n",
        "        classname = self.filenames_classnames[index][1]\n",
        "        classid = self.classnames_to_ids[classname]\n",
        "        return resized_image, classid, classname, self.image_filepaths[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filepaths)\n",
        "\n",
        "def to_grayscale(pil_image):\n",
        "    if pil_image.ndim == 2:\n",
        "        return pil_image.copy()[None]\n",
        "    if pil_image.ndim != 3:\n",
        "        raise ValueError(\"image must have either shape (H, W) or (H, W, 3)\")\n",
        "    if pil_image.shape[2] != 3:\n",
        "        raise ValueError(f\"image has shape (H, W, {pil_image.shape[2]}), but it should have (H, W, 3)\")\n",
        "\n",
        "    rgb = pil_image / 255\n",
        "    rgb_linear = np.where(\n",
        "        rgb < 0.04045,\n",
        "        rgb / 12.92,\n",
        "        ((rgb + 0.055) / 1.055) ** 2.4\n",
        "    )\n",
        "    grayscale_linear = 0.2126 * rgb_linear[..., 0] + 0.7152 * rgb_linear[..., 1] + 0.0722 * rgb_linear[..., 2]\n",
        "\n",
        "    grayscale = np.where(\n",
        "        grayscale_linear < 0.0031308,\n",
        "        12.92 * grayscale_linear,\n",
        "        1.055 * grayscale_linear ** (1 / 2.4) - 0.055\n",
        "    )\n",
        "    grayscale = grayscale * 255\n",
        "\n",
        "    if np.issubdtype(pil_image.dtype, np.integer):\n",
        "        grayscale = np.round(grayscale)\n",
        "    return grayscale.astype(pil_image.dtype)[None]\n",
        "\n",
        "def prepare_image(image, width, height, x, y, size):\n",
        "    if image.ndim < 3 or image.shape[-3] != 1:\n",
        "        raise ValueError(\"image must have shape (1, H, W)\")\n",
        "    if width < 32 or height < 32 or size < 32:\n",
        "        raise ValueError(\"width/height/size must be >= 32\")\n",
        "    if x < 0 or (x + size) > width:\n",
        "        raise ValueError(f\"x={x} and size={size} do not fit into the resized image width={width}\")\n",
        "    if y < 0 or (y + size) > height:\n",
        "        raise ValueError(f\"y={y} and size={size} do not fit into the resized image height={height}\")\n",
        "\n",
        "    image = image.copy()\n",
        "\n",
        "    if image.shape[1] > height:\n",
        "        image = image[:, (image.shape[1] - height) // 2: (image.shape[1] - height) // 2 + height, :]\n",
        "    else:\n",
        "        image = np.pad(image, ((0, 0), ((height - image.shape[1])//2, np.ceil((height - image.shape[1])/2)), (0, 0)), mode='edge')\n",
        "\n",
        "    if image.shape[2] > width:\n",
        "        image = image[:, :, (image.shape[2] - width) // 2: (image.shape[2] - width) // 2 + width]\n",
        "    else:\n",
        "        image = np.pad(image, ((0, 0), (0, 0), ((width - image.shape[2])//2, np.ceil((width - image.shape[2])/2))), mode='edge')\n",
        "\n",
        "    subarea = image[:, y:y + size, x:x + size]\n",
        "    return image, subarea"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpaOW13RLqaU",
        "outputId": "17f99513-e033-48d5-e858-3e76ae490c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Model Architecture in architecture.py\n",
        "%%writefile architecture.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, num_classes=20):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 12 * 12, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 12 * 12)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MyCNN(num_classes=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWSnBG09L03B",
        "outputId": "42369daf-6551-4332-cbf8-d1de48fb425b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting architecture.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model and Save the Trained Model\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from dataset import ImagesDataset\n",
        "from architecture import MyCNN, model\n",
        "\n",
        "# Define data directory and load dataset\n",
        "data_dir = '/content/drive/My Drive/training_data'\n",
        "\n",
        "train_dataset = ImagesDataset(image_dir=data_dir, dtype=np.uint8)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels, _, _ in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO3l_BnnL42h",
        "outputId": "1038dc4a-0e12-4523-e47f-1f1dcf1bef52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.4780\n",
            "Epoch [2/10], Loss: 1.9194\n",
            "Epoch [3/10], Loss: 1.6156\n",
            "Epoch [4/10], Loss: 1.3288\n",
            "Epoch [5/10], Loss: 1.0322\n",
            "Epoch [6/10], Loss: 0.7235\n",
            "Epoch [7/10], Loss: 0.4665\n",
            "Epoch [8/10], Loss: 0.3007\n",
            "Epoch [9/10], Loss: 0.1979\n",
            "Epoch [10/10], Loss: 0.1537\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Trained Model to Google Drive\n",
        "!cp model.pth /content/drive/My\\ Drive/model.pth"
      ],
      "metadata": {
        "id": "vPTVGusCL8H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Trained Model\n",
        "model = MyCNN(num_classes=20)\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/model.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcduS8TRS91K",
        "outputId": "c6c5f979-ffd3-4ce8-d1e7-f0010a0b21df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=18432, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Function to Make Predictions on New Images\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def predict_image(image_path, model, classnames):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((100, 100)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        classname = classnames[predicted.item()]\n",
        "    return classname"
      ],
      "metadata": {
        "id": "09Ytr-5nS98_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Model with Various Images\n",
        "classnames = list(train_dataset.classnames_to_ids.keys())\n",
        "test_image_path = '/content/drive/My Drive/training_data/0001661.jpg'  # Replace with the path to your test image\n",
        "predicted_class = predict_image(test_image_path, model, classnames)\n",
        "print(f'The predicted class for the test image is: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgdwVg2oS9-4",
        "outputId": "4f4141eb-2f9e-4dfb-b1bc-0e067026557f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class for the test image is: tree\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-dstdSue-VL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}